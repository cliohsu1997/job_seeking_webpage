# Structure: Project Organization

## Project Structure Overview

```
job-seeking-webpage/
â”œâ”€â”€ read_it.md                      # Project guidelines (read first)
â”œâ”€â”€ pyproject.toml                  # Poetry configuration
â”œâ”€â”€ README.md                       # Project documentation
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                        # Raw scraped HTML/XML (Phase 1 output)
â”‚   â”‚   â”œâ”€â”€ aea/                    # AEA JOE scraped files
â”‚   â”‚   â”œâ”€â”€ universities/           # University scraped files
â”‚   â”‚   â”œâ”€â”€ institutes/             # Research institute scraped files
â”‚   â”‚   â””â”€â”€ documents/              # Downloaded documents (PDFs, Word, Excel, text files)
â”‚   â”œâ”€â”€ processed/                  # Processed data (Phase 2 output)
â”‚   â”‚   â”œâ”€â”€ jobs.json               # Current listings
â”‚   â”‚   â”œâ”€â”€ jobs.csv                # Current listings (CSV)
â”‚   â”‚   â”œâ”€â”€ archive/                # Historical snapshots
â”‚   â”‚   â””â”€â”€ diagnostics/            # Diagnostic reports
â”‚   â””â”€â”€ config/
â”‚       â”œâ”€â”€ README.md               # Configuration guide with verification methodology
â”‚       â”œâ”€â”€ scraping_sources.json   # âœ… FLAT structure: 127 accessible + 83 non-accessible = 210 entries
â”‚       â”‚                           # Format: {"accessible": [{"id": "...", "url": "...", "type": "...", ...}], "non_accessible": [...]}
â”‚       â”œâ”€â”€ scraping_rules.json     # Scraping patterns
â”‚       â”œâ”€â”€ processing_rules.json   # Processing rules
â”‚       â”œâ”€â”€ url_replacements.json   # URL replacement patterns
â”‚       â””â”€â”€ url_verification/       # âœ… URL verification results and documentation
â”‚           â”œâ”€â”€ README.md           # Folder documentation
â”‚           â””â”€â”€ verification_results.md  # Latest verification results summary
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ scraper/                    # Phase 1 - COMPLETE
â”‚   â”‚   â”œâ”€â”€ base_scraper.py         # Base scraper class
â”‚   â”‚   â”œâ”€â”€ aea_scraper.py          # AEA JOE scraper
â”‚   â”‚   â”œâ”€â”€ university_scraper.py   # University scraper
â”‚   â”‚   â”œâ”€â”€ institute_scraper.py    # Institute scraper
â”‚   â”‚   â”œâ”€â”€ parsers/                # HTML, RSS, text, date parsers
â”‚   â”‚   â”œâ”€â”€ utils/                  # Rate limiter, retry handler, user agent
â”‚   â”‚   â””â”€â”€ config/                 # âœ… PHASE 1B - Configuration verification tools
â”‚   â”‚       â”œâ”€â”€ README.md                     # Documentation for verification tools
â”‚   â”‚       â”œâ”€â”€ url_access/                   # âœ… Task 0A - HTTP accessibility testing (COMPLETE)
â”‚   â”‚       â”‚   â”œâ”€â”€ __init__.py               # Module exports
â”‚   â”‚       â”‚   â”œâ”€â”€ test_accessibility.py     # âœ… HTTP connectivity testing
â”‚   â”‚       â”‚   â”œâ”€â”€ redirect_handler.py       # âœ… Redirect following & chain tracking
â”‚   â”‚       â”‚   â”œâ”€â”€ dns_resolver.py           # âœ… Chinese DNS fallback support
â”‚   â”‚       â”‚   â””â”€â”€ connectivity_report.py    # âœ… Generate accessibility reports
â”‚   â”‚       â””â”€â”€ url_verification/             # Task 0B - Content validation (pending)
â”‚   â”‚           â””â”€â”€ (to be implemented)       # Page classifier, content validator, quality scorer, etc.
â”‚   â”œâ”€â”€ processor/                  # Phase 2 - âœ… COMPLETE
â”‚   â”‚   â”œâ”€â”€ pipeline.py            # Main pipeline (âœ… Phase 2E - full integration with archive retention)
â”‚   â”‚   â”œâ”€â”€ parser_manager.py       # Route to parsers (âœ… Phase 2A)
â”‚   â”‚   â”œâ”€â”€ normalizer.py           # Data normalization (âœ… Phase 2B)
â”‚   â”‚   â”œâ”€â”€ enricher.py             # Data enrichment (âœ… Phase 2B)
â”‚   â”‚   â”œâ”€â”€ deduplicator.py         # Deduplication (âœ… Phase 2C)
â”‚   â”‚   â”œâ”€â”€ validator.py            # Data validation (âœ… Phase 2D)
â”‚   â”‚   â”œâ”€â”€ schema.py               # Schema definition (âœ… created)
â”‚   â”‚   â”œâ”€â”€ diagnostics.py          # Diagnostic tracking & reports (âœ… Phase 2A, 2D)
â”‚   â”‚   â””â”€â”€ utils/                  # ID generator (âœ…), location parser (âœ…), text cleaner (âœ…)
â”‚   â”œâ”€â”€ generator/                  # Phase 3 - âœ… COMPLETE (MVP)
â”‚   â”‚   â”œâ”€â”€ __init__.py            # Generator module init (exports)
â”‚   â”‚   â”œâ”€â”€ build_site.py          # Static site builder (178 lines, CLI support)
â”‚   â”‚   â””â”€â”€ template_renderer.py   # Jinja2 renderer with custom filters (313 lines + json_dumps)
â”‚   â””â”€â”€ scheduler.py                # Phase 4 - PENDING
â”‚
â”œâ”€â”€ tests/                          # Tests organized by phase
â”‚   â”œâ”€â”€ setup-project/              # Phase 0 tests
â”‚   â”œâ”€â”€ load-data-collection/       # Phase 1 tests
â”‚   â”‚   â”œâ”€â”€ README.md                       # Phase 1 test documentation
â”‚   â”‚   â”œâ”€â”€ config/                         # âœ… Configuration and URL verification tests
â”‚   â”‚   â”‚   â”œâ”€â”€ test_scraping_sources.py    # Validate scraping sources config
â”‚   â”‚   â”‚   â”œâ”€â”€ test_config_loader.py       # Test config loader utility
â”‚   â”‚   â”‚   â”œâ”€â”€ url_access/                 # âœ… Task 0A - URL access verification tests
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ test_accessibility.py   # Test HTTP connectivity
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ test_redirects.py       # Test redirect following
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ test_connectivity_report.py  # Test report generation
â”‚   â”‚   â”‚   â””â”€â”€ url_verification/           # Task 0B - URL content validation tests (pending)
â”‚   â”‚   â”œâ”€â”€ scraper/                        # Scraper tests
â”‚   â”‚   â”œâ”€â”€ parser/                         # Parser tests
â”‚   â”‚   â””â”€â”€ utils/                          # Utility tests
â”‚   â”œâ”€â”€ transform-data-processing/  # Phase 2 tests
â”‚   â”‚   â”œâ”€â”€ parser/                 # Parser manager tests (âœ… Phase 1 integration)
â”‚   â”‚   â”œâ”€â”€ utils/                  # Utility tests (âœ… location parser, 41 tests)
â”‚   â”‚   â”œâ”€â”€ normalizer/             # Normalizer tests (âœ… 28 tests, all passing)
â”‚   â”‚   â”œâ”€â”€ enricher/               # Enricher tests (âœ… 24 tests, all passing)
â”‚   â”‚   â”œâ”€â”€ deduplicator/           # Deduplicator tests (âœ… Phase 2C)
â”‚   â”‚   â”œâ”€â”€ validator/              # Validator tests (âœ… Phase 2D, 26 tests)
â”‚   â”‚   â””â”€â”€ integration/           # Integration tests (âœ… Phase 2A components)
â”‚   â””â”€â”€ export-output-generation/   # Phase 3 tests (to be created)
â”‚
â”œâ”€â”€ templates/                      # HTML templates (Phase 3 - âœ… COMPLETE + specialization filter)
â”‚   â””â”€â”€ index.html.jinja           # Main page Jinja2 template (348 lines, all UI components + specialization filter)
â”œâ”€â”€ static/                         # CSS, JS, images (Phase 3 - âœ… COMPLETE + specialization filter)
â”‚   â”œâ”€â”€ index.html                 # Generated static page (âœ“ 25,448 insertions)
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ styles.css             # Responsive styles (mobile-first, 3 breakpoints)
â”‚   â”œâ”€â”€ js/
â”‚   â”‚   â”œâ”€â”€ app.js                # Main app logic (355 lines, optimized - no debug logs)
â”‚   â”‚   â”œâ”€â”€ filters.js            # Filtering functionality (323 lines, optimized - no debug logs, 5 filter types)
â”‚   â”‚   â””â”€â”€ search.js             # Search functionality (121 lines, optimized - no debug logs, debounced)
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ jobs.json             # Client-side data copy (211 listings with specializations)
â”‚   â””â”€â”€ images/                   # Icons, logos
â”‚
â””â”€â”€ conversation_cursor/            # Project management
    â”œâ”€â”€ dates/                      # Dated proposals
    â”œâ”€â”€ progress/latest.md         # High-level pipeline status
    â”œâ”€â”€ structure/latest.md         # This file - project structure
    â””â”€â”€ to-do-list/                 # Detailed task lists

.github/                            # GitHub configuration
â””â”€â”€ workflows/
    â””â”€â”€ gh-pages.yml               # GitHub Pages workflow (âœ… active, deploys /static)
```

## Key Files & Modules

### Configuration
- **`data/config/scraping_sources.json`**: 176+ accessible URLs across job portals (AEA JOE, HigherEdJobs, EconJobMarket, EJMR, AEA Scramble), universities, research institutes. **Rule**: Only URLs containing relevant job information should be in accessible section. **Status**: 81 URLs currently have issues (47 moved to non_accessible, 34 in non_accessible with issues) - see verification results. **Phase 1B Challenge**: Many URLs point to wrong page types (department pages, faculty directories) instead of actual career portals - requires URL discovery to find correct job pages. **IMPORTANT**: Only update URLs in `non_accessible` section - accessible URLs are working fine and should remain unchanged. Initial fixes completed for Chinese and international universities in non_accessible section; remaining URLs (US universities, etc.) to be fixed later.
- **`data/config/scraping_rules.json`**: Scraping patterns (deadlines, keywords, date formats)
- **`data/config/processing_rules.json`**: Processing rules (job type keywords, specialization keywords, region mapping, materials parsing)
- **`scripts/scraper/check_config/verify_urls.py`**: URL verification script that checks accessible and non_accessible URLs, verifies job content (keywords, links, PDFs), and moves invalid URLs to non_accessible section
- **`scripts/scraper/check_config/find_url_replacements.py`**: Helper script to find replacement URLs by testing common URL patterns (jobs.*, careers.*, etc.) for problematic universities
- **`data/config/URL_VERIFICATION.md`**: Documentation for URL verification process and common patterns

### Scraper Framework (Phase 1 - Complete, Phase 1B - In Progress)
- **`scripts/scraper/main.py`**: Main script to scrape all accessible sources (universities, institutes, AEA) with one command âœ…
- **Phase 1B - Expand Sources** (ğŸ”„ In Progress): Expanding from 176 to 250+ URLs with better global coverage
- **`scripts/scraper/base_scraper.py`**: Abstract base class (fetch, parse, extract, save)
- **`scripts/scraper/aea_scraper.py`**: AEA JOE scraper (RSS/HTML fallback). **Phase 2F**: Immediate URL resolution âœ…
- **`scripts/scraper/university_scraper.py`**: Generic university scraper (pattern-based, **link-following enabled** - automatically follows links to detail pages to extract full job information). **Phase 2F**: Enhanced requirements and materials extraction, always sets source_url, immediate URL resolution âœ…
- **`scripts/scraper/institute_scraper.py`**: Research institute scraper (**link-following enabled** - automatically follows links to detail pages). **Phase 2F**: Always sets source_url, immediate URL resolution âœ…
- **`scripts/scraper/parsers/html_parser.py`**: HTML parser with **immediate URL resolution** - extract_links() resolves relative URLs to absolute URLs immediately using base_url parameter âœ…
- **`scripts/scraper/parsers/`**: HTML, RSS, text extractor, date parser
- **`scripts/scraper/utils/`**: Rate limiter, retry handler, user agent, config loader

### Processor Framework (Phase 2 - âœ… Complete)
- **`scripts/processor/pipeline.py`**: Main processing pipeline orchestrator (full workflow: parse â†’ normalize â†’ enrich â†’ deduplicate â†’ validate â†’ diagnostics, JSON/CSV output, archive with retention)
- **`scripts/processor/parser_manager.py`**: Routes raw data to parsers âœ… Phase 2A. **Phase 2F**: Base URL lookup from config (with partial name matching), ensures source fields always set, enhanced file reading with chardet âœ…
- **`scripts/processor/normalizer.py`**: Normalizes dates, locations, formats, text, job types, departments, contact info, materials âœ… Phase 2B. **Phase 2F**: Enhanced URL resolution with base URLs from parser manager (highest priority), relative URL resolution with fallbacks, better handling of relative URLs with/without leading `/` âœ…
- **`scripts/processor/enricher.py`**: Enriches data (IDs, classifications, metadata, specializations) âœ… Phase 2B. **Phase 2F**: Sets default values for optional fields âœ…
- **`scripts/processor/deduplicator.py`**: Identifies and merges duplicate listings (fuzzy matching, merge logic, new/active detection) âœ… Phase 2C
- **`scripts/processor/validator.py`**: Validates data against schema (schema validation, date/URL validation, completeness/quality/consistency checks, batch validation) âœ… Phase 2D. **Phase 2F**: Tiered validation - optional fields treated as warnings instead of critical errors âœ…
- **`scripts/processor/diagnostics.py`**: Diagnostic tracking and root cause analysis âœ… Phase 2A, report generation (root cause analysis, category statistics, JSON/text output, file saving) âœ… Phase 2D
- **`scripts/processor/schema.py`**: Data schema definition (29 fields, validation functions) âœ…. **Phase 2F**: Moved non-critical fields (deadline, description, requirements, specializations, application_link, materials_required) to optional âœ…
- **`scripts/processor/utils/`**: ID generator âœ…, location parser âœ…, text cleaner âœ…
- **`scripts/processor/pipeline.py`**: Main processing pipeline orchestrator âœ… Phase 2A
- **`scripts/processor/parser_manager.py`**: Routes raw data to parsers âœ… Phase 2A (Phase 1 integration complete)
- **`scripts/processor/normalizer.py`**: Basic data normalization âœ… Phase 2A

## Workflow

**Load â†’ Transform â†’ Export**
1. **LOAD**:
   - **Phase 1 (âœ…)**: Scrape raw HTML from sources (176 URLs)
   - **Phase 1B (ğŸ”„)**: Expand sources to 250+ URLs with better global coverage
2. **TRANSFORM (Phase 2 - âœ…)**: Process, normalize, deduplicate, validate data (complete pipeline with archive retention)
3. **EXPORT (Phase 3 - âœ…)**: Generate static webpage with filters, search, and responsive design (static/index.html, styles.css, app.js, filters.js, search.js)
4. **DEPLOY (Phase 4 - â¸ï¸)**: Automation and hosting (GitHub Pages)

## Environment

- **Python**: 3.13.5 (via Poetry)
- **Virtual Environment**: `./environment/python/venv/`
- **Run**: `poetry run python scripts/scraper/aea_scraper.py`
